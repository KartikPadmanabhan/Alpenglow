Five minute tutorial
====================

In this tutorial we are going to learn the basic concepts of using Alpenglow by evaluating various baseline models on real world data and then building a simple combined model.

The data
--------

You can find the dataset [todo]. This is a processed version of the 30M dataset [todo], where we

- only keep users above a certain activity threshold
- only keep the first events of listening sessions
- recode the items so they represent artists instead of tracks

Let's start by importing the csv using pandas.


.. role:: python(code)
   :language: python

.. code-block:: python

	import pandas as pd
	data = pd.read_csv('artist_data_10_1800')
	print(data.columns)

Output::

	Index(['time', 'user', 'item', 'score', 'eval', 'category'], dtype='object')

To run online experiments, you will need time-series data of user-item interactions in similar format to the above. The only required columns are the :python:`'user'` and :python:`'item'` columns -- the rest will be autofilled if missing. The most important columns are the following:

- **time**: integer, the timestamp of the record. Controls various things, like evaluation timeframes or batch learning epochs. Defaults to :python:`range(0,len(data))` if missing.
- **user**: integer, the user the activity belongs to. This column is required.
- **item**: integer, the item the activity belongs to. This column is required.
- **score**: double, the score corresponding to the given record. This could be for example the rating of the item in the case of explicit recommendation. Defaults to constant :python:`1`.
- **eval**: boolean, whether to run ranking-evaluation on the record. Defaults to constant :python:`True`.

Our first model
---------------

Let's start by evaluating a very basic model on the dataset, the popularity model. To do this, we need to import the preconfigured experiment from the package :py:mod:`alpenglow.experimens`.

.. code-block:: python

	from alpenglow.experiments import PopularityModelExperiment

When creating an instance of the experiment, we can provide various configuration options and parameters.

.. code-block:: python

	pop_experiment = PopularityModelExperiment(
	    top_k=100, # we are going to evaluate on top 100 ranking lists
	    seed=12345, # for reproducibility, we provide a random seed
	)

You can see the list available options of online experiments in the documentation of :py:class:`alpenglow.OnlineExperiment` and the parameters of this particular experiment in the documentation of the specific implementation (in this case :py:class:`alpenglow.experiments.PopularityModelExperiment`) or, failing that, in the source code of the given class.

Running the experiment on the data is as simple as calling :python:`run(data)`. Multiple options can be provided at this point, for a full list, refer to the documentation of :py:meth:`alpenglow.OnlineExperiment.OnlineExperiment.run`.

.. code-block:: python

	result = pop_experiment.run(data, verbose=True) #this might take a while

The :python:`run()` method first builds the experiment out of C++ components according to the given parameters, then processes the data, training on it and evaluating the model at the same time. The returned object is a :py:class:`pandas.DataFrame` object, which contains various information regarding the results of the experiment:


.. code-block:: python

	print(result.columns)

Output::

	Index(['time', 'score', 'user', 'item', 'prediction', 'rank'], dtype='object')

Prediction is the score estimate given by the model and rank is the rank of the item in the toplist generated by the model. If the item is not on the toplist, rank is :python:`NaN`.

The easiest way interpret the results is by using a predefined evaluator, for example :py:class:`alpenglow.evaluation.DcgScore`:


.. code-block:: python

	from alpenglow.evaluation import DcgScore
	results['dcg'] = DcgScore(results)

The :py:class:`DcgScore` class calculates the NDCG values for the given ranks and returns a :py:class:`pandas.Series` object. This can be averaged and plotted easily to visualize the performance of the recommender model.


.. code-block:: python

	daily_avg_dcg = results['dcg'].groupby((results['time']-results['time'].min())//86400).mean()
	daily_avg_dcg.plot()

[todo plot]

Putting it all together:

.. code-block:: python

	import pandas as pd
	from alpenglow.evaluation import DcgScore
	from alpenglow.experiments import PopularityModelExperiment

	data = pd.read_csv('artist_data_10_1800')

	pop_experiment = PopularityModelExperiment(
	    top_k=100,
	    seed=12345,
	)
	results = pop_experiment.run(data, verbose=True)
	results['dcg'] = DcgScore(results)
	results['dcg'].groupby((results['time']-results['time'].min())//86400).mean().plot()

Matrix factorization, hyperparameter search
-------------------------------------------

The :py:class:`alpenglow.experiments.FactorModelExperiment` class implements a factor model, which is updated in an online fashion. After checking the documentation / source, we can see that the most relevant hyperparameters for this model are :python:`dimension` (the number of latent factors), :python:`learning_rate`, :python:`negative_rate` and :python:`regularization_rate`. For this experiment, we are not going to increase the default value of 10 for the factor dimension, and we are not going to need regularization, so we'll leave it at its default (0) as well. The learning rate and the negative rate will probably have to be tweaked.

.. code-block:: python

	from alpenglow.experiments import FactorModelExperiment

	mf_experiment = FactorModelExperiment(
	    top_k=100,
	)
	mf_results = mf_experiment.run(data, verbose=True)
	mf_results['dcg'] = DcgScore(mf_results)
	mf_daily_avg = mf_results['dcg'].groupby((mf_results['time']-mf_results['time'].min())//86400).mean().plot()

